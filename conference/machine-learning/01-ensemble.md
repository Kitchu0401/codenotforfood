# 앙상블 : ML의 끝판왕, 파라미터의 최적화 삽질에서 벗어나자 StackNet (캐글 상위권 도전기) - 김연민

- 지각..

## Kaggle에 대한 소개

## 사례 소개
2 시그마 커넥트 x RentHop
RentHop의 임대리스트에 사람들이 얼마나 관심을 가질지

- 객실에 대한 이미지 데이터를 받음 (토렌트) - 실제로 문제 푸는데에 사용한 사람 적음
- 데이터를 관찰 - 피처 엔지니어링
- 점진적으로 피처를 만들고 / 테스트
  피쳐 엔지니어링 : 데이터의 도메인 지식을 사용하여 기계학습 알고리즘을 작동시키는 피쳐를 만드는 프로세스

  기존에 있는 데이터의 변수를 가공, 새로운 피쳐 만들거나 변형

  - 데이터 본질 파악
  - Missing Value 처리
  - 아웃라이어 (주: 기존의 값을 보충하는 값들?)
  - 피쳐엔지니어링
  - 커널 & 디스커션 : 사람들의 다양한 의견 참고
  - 매직 피쳐? 예기치 않게 누출되는 정보 - 이미지 폴더 생성 시간

모델에 반영
모델을 스태킹

1. 데이터 처리

할 수 있는 데이터 분할 작업을 자잘하게 모두 해봄
날짜 쪼개기, 방당 가격, 위도와 경도당 방 가격, 부동산 중개업자와의 관계 등등
기존 랭킹에서의 처리방식도 참고
평면도와 이미지 분류 - 평면도는 흰색과 검은색을 주로 사용 - 색의 표준편차가 큼

2. 다양한 알고리즘의 사용
같은 데이터 셋이라도 서로 예측한 결과가 다르기 때문
각 알고리즘의 모자란 부분들을 서로 보완해주는 느낌

  1. Stacking
  동일한 크기의 데이터를 여러개 받아 투표하여 오차를 수정하는 가장 단순한 방법

  2. 앙상블
  여러 알고리즘의 결과를 섞어 장점을 취하고 단점을 보완하는 기법?

3. 어떤 알고리즘을?
모든 것은 하이퍼 파라미터, 정해진거 x 최대한 실험
- 어떤 모델을 사용해야 하는지
- 어떻게 결합할 것인지
- 중간에 데이터 추가할 것인지
- 제출 결과를 어떻게 계수
- 이를 산출하기 위해 [라이브러리](https://github.com/kaz-Anova/StackNet)도 개발됨

시간을 다투는 상황에선 하이퍼파라미터 튜닝을 통한 알고리즘의 성능 강화보단

다양한 피쳐엔지니어링을 통해 다양성을 확보,

결과 간의 상관관계를 분석하여 조화롭게 사용하는 것이 중요한 것 같습니다.

## Kaggle 팁
[LightGBM](https://github.com/Microsoft/LightGBM): Xgboost보다 수행시간이 1/10 수준, FE에 최적화됨!

집 컴퓨터가 좋지 않으면 AWS p2 인스턴스 굳굳 (시간당 0.9달러)

제출 기회를 최대한 활용하세요
- 피쳐 엔지니어링 다양성 확보와 연결
- 개인적으로 산출한 score와 실제 제출결과가 상이 할 수 있기 때문

끝나고 우승자 솔루션, 대회에서 배운 것을 정리하는건 필수
